# SPOD_PARCE_LOAD - Система обработки данных конкурсов

## Описание проекта

SPOD_PARCE_LOAD - это система для обработки данных конкурсов, групп и индикаторов. Программа читает CSV файлы из каталога SPOD, обрабатывает JSON поля, объединяет данные и создает итоговый Excel файл с результатами.

## Основные возможности

- Чтение и обработка CSV файлов с данными конкурсов
- Разворачивание JSON полей в отдельные колонки
- Объединение данных из разных источников (MERGE_FIELDS и MERGE_FIELDS_ADVANCED)
- Создание итогового Excel файла с форматированием и цветовым кодированием
- Проверка дубликатов данных с автоматической пометкой
- Поддержка нечувствительности к регистру при загрузке файлов
- Двухуровневое логирование (файл и консоль)
- Детальное логирование с указанием функции-источника

## Структура проекта

```
SPOD_PARCE_LOAD/
├── main.py                    # Основная программа
├── generate_employee_data.py  # Генератор данных сотрудников
├── SPOD/                      # Входные данные (CSV файлы)
├── OUT/                       # Выходные файлы (Excel)
├── LOGS/                      # Логи работы программы
├── venv/                      # Виртуальное окружение Python
├── .git/                      # Git репозиторий
├── .gitignore                 # Игнорируемые файлы Git
└── README.md                  # Документация проекта
```

## Установка и настройка

### 1. Создание виртуального окружения

```bash
python3 -m venv venv
source venv/bin/activate  # На Linux/macOS
# или
venv\Scripts\activate     # На Windows
```

### 2. Установка зависимостей

```bash
pip install pandas openpyxl
```

### 3. Подготовка данных

Поместите CSV файлы в каталог `SPOD/`:
- `CONTEST-DATA (PROM) 2025-10-08 v1.csv` - данные конкурсов
- `GROUP (PROM) 2025-10-08 v0.csv` - данные групп  
- `INDICATOR (PROM) 2025-10-07 v0.csv` - данные индикаторов
- `REPORT (PROM) 2025-10-08 v0.csv` - данные отчетов
- `REWARD (PROM) 2025-10-08 v0.csv` - данные наград
- `TOURNAMENT-SCHEDULE (PROM) 2025-10-08 v0.csv` - расписание турниров
- И другие файлы согласно конфигурации

## Использование

### Запуск основной программы

```bash
python main.py
```

### Запуск генератора данных сотрудников

```bash
python generate_employee_data.py
```

## Конфигурация

### Входные файлы

Программа настроена на обработку следующих файлов:

1. **CONTEST-DATA (PROM) 2025-10-08 v1.csv**
   - Лист: CONTEST-DATA
   - Максимальная ширина колонки: 120
   - Закрепление области: C2

2. **GROUP (PROM) 2025-10-08 v0.csv**
   - Лист: GROUP
   - Максимальная ширина колонки: 20
   - Закрепление области: C2

3. **INDICATOR (PROM) 2025-10-07 v0.csv**
   - Лист: INDICATOR
   - Максимальная ширина колонки: 100
   - Закрепление области: B2

### Поддержка нечувствительности к регистру

Программа автоматически находит файлы независимо от регистра расширения:
- `.csv`, `.CSV`, `.Csv` - все варианты поддерживаются
- Имена файлов также нечувствительны к регистру

## Логирование

### Двухуровневая система логирования

Программа использует два обработчика логирования:

1. **Файловый обработчик** (уровень DEBUG):
   - Записывает ВСЕ логи, включая DEBUG, в файл
   - Формат: `LOGS_LEVEL_YYYYMMDD_HH_MM.log`
   - Пример: `LOGS_DEBUG_20251114_00_52.log`
   - Каждая строка содержит имя функции, вызвавшей логирование: `[def: имя_функции]`

2. **Консольный обработчик** (уровень INFO):
   - Выводит только INFO, WARNING, ERROR в консоль
   - DEBUG сообщения в консоль не выводятся
   - Формат: `%(asctime)s | %(levelname)s | %(message)s`

### Формат логов

**В файле:**
```
2025-11-14 00:52:30 | INFO | Файл успешно загружен: SPOD/CONTEST-DATA.csv [def: read_csv_file]
2025-11-14 00:52:31 | DEBUG | Разворачивание колонки CONTEST_FEATURE [def: flatten_json_column]
```

**В консоли:**
```
2025-11-14 00:52:30 | INFO | Файл успешно загружен: SPOD/CONTEST-DATA.csv
2025-11-14 00:52:31 | WARNING | Колонка не найдена в листе
```

### Уровни логирования

- **DEBUG**: Подробная отладочная информация (только в файл)
- **INFO**: Основные сообщения о ходе выполнения (файл и консоль)
- **WARNING**: Предупреждения (файл и консоль)
- **ERROR**: Ошибки (файл и консоль)

### Настройка уровня логирования

В файле `main.py` установите переменную:
```python
LOG_LEVEL = "DEBUG"  # Для отладки
# или
LOG_LEVEL = "INFO"  # Для продакшена
```

## Выходные файлы

Результаты работы сохраняются в каталоге `OUT/`:
- `SPOD_ALL_IN_ONE_YYYY-MM-DD_HH-MM-SS.xlsx` - итоговый файл с данными
- Файлы содержат форматированные листы с данными конкурсов, групп и индикаторов
- Лист SUMMARY содержит сводную информацию по всем данным

## Технические особенности

### Обработка JSON полей

Программа автоматически разворачивает JSON поля в отдельные колонки:
- `CONTEST_FEATURE` поля разворачиваются с префиксом `CONTEST_FEATURE =>`
- `REWARD_ADD_DATA` поля разворачиваются с префиксом `ADD_DATA =>`

### Объединение данных (MERGE_FIELDS)

Программа использует два типа правил объединения:

1. **MERGE_FIELDS** - базовые правила объединения данных между листами
2. **MERGE_FIELDS_ADVANCED** - расширенные правила с поддержкой:
   - Фильтрации по статусам
   - Пользовательских условий
   - Группировки и агрегации

### Проверка дубликатов (CHECK_DUPLICATES)

Программа автоматически проверяет дубликаты данных:
- Для каждого листа из CHECK_DUPLICATES создается колонка с пометкой дублей
- Имя колонки: `ДУБЛЬ: КЛЮЧ1_КЛЮЧ2_...` (формируется из ключей проверки)
- Значения: `x2`, `x3`, `x4` и т.д. (количество дублей) или пустая строка для уникальных
- Колонки с дублями выделяются розовым цветом в Excel
- Для листов с несколькими записями в CHECK_DUPLICATES создаются отдельные колонки для каждого варианта проверки

### Цветовое кодирование

Используется динамическая цветовая схема для визуального разделения данных:
- Разные цвета для разных типов полей
- Автоматическое определение цветов на основе содержимого
- Специальная цветовая схема для колонок с дублями (розовый)

### Обработка ошибок

- Проверка существования входных файлов
- Валидация данных при обработке
- Подробное логирование ошибок с указанием функции-источника
- Graceful handling несуществующих файлов

## Основные функции и переменные

### Глобальные переменные

- `DIR_INPUT` - каталог с входными файлами (SPOD/)
- `DIR_OUTPUT` - каталог для выходных файлов (OUT/)
- `DIR_LOGS` - каталог для логов (LOGS/)
- `LOG_LEVEL` - уровень логирования ("DEBUG" или "INFO")
- `LOG_BASE_NAME` - базовое имя для файлов логов ("LOGS")

### Конфигурационные структуры

- `MERGE_FIELDS` - список правил объединения данных между листами
- `MERGE_FIELDS_ADVANCED` - расширенные правила объединения с фильтрацией и группировкой
- `CHECK_DUPLICATES` - список правил проверки дубликатов
- `COLOR_SCHEMES` - цветовые схемы для форматирования Excel
- `JSON_COLUMNS` - правила разворачивания JSON полей

### Основные функции

#### `setup_logger()`
Настраивает систему логирования с двумя обработчиками:
- Файловый: уровень DEBUG, формат с именем функции
- Консольный: уровень INFO, формат без имени функции

**Возвращает:** путь к созданному лог-файлу

#### `read_csv_file(file_path)`
Читает CSV файл и возвращает DataFrame.

**Параметры:**
- `file_path` (str): путь к CSV файлу

**Возвращает:** pandas.DataFrame с данными

#### `flatten_json_column(df, column, prefix, sheet_name)`
Разворачивает JSON колонку в отдельные колонки.

**Параметры:**
- `df` (DataFrame): исходный DataFrame
- `column` (str): имя JSON колонки
- `prefix` (str): префикс для новых колонок
- `sheet_name` (str): имя листа (для логирования)

**Возвращает:** DataFrame с развернутыми колонками

#### `mark_duplicates(df, key_cols, sheet_name)`
Добавляет колонку с пометкой дублей по указанным ключам.

**Параметры:**
- `df` (DataFrame): исходный DataFrame
- `key_cols` (list): список колонок для проверки дублей
- `sheet_name` (str): имя листа (для логирования)

**Возвращает:** DataFrame с добавленной колонкой `ДУБЛЬ: КЛЮЧ1_КЛЮЧ2_...`

**Пример:**
```python
df = mark_duplicates(df, ["CONTEST_CODE"], "CONTEST-DATA")
# Создает колонку "ДУБЛЬ: CONTEST_CODE" со значениями "x2", "x3" и т.д.
```

#### `merge_fields_across_sheets(sheets_data, merge_fields)`
Объединяет данные между листами согласно правилам MERGE_FIELDS.

**Параметры:**
- `sheets_data` (dict): словарь с данными листов
- `merge_fields` (list): список правил объединения

#### `write_to_excel(sheets_data, output_path)`
Записывает данные в Excel файл с форматированием.

**Параметры:**
- `sheets_data` (dict): словарь с данными листов
- `output_path` (str): путь к выходному файлу

#### `build_summary_sheet(dfs, params_summary, merge_fields)`
Создает итоговый лист SUMMARY с объединенными данными.

**Параметры:**
- `dfs` (dict): словарь с данными всех листов
- `params_summary` (dict): параметры листа SUMMARY
- `merge_fields` (list): правила объединения для SUMMARY

**Возвращает:** DataFrame с данными листа SUMMARY

## История версий

### Версия 2.0 (Текущая) - 2025-11-14

#### Основные изменения:
- ✅ Удалены листы SUMMARY_REWARD, SUMMARY_CONTEST, SUMMARY_SCHEDULE
- ✅ Удалена функция `create_unique_summary_sheet()`
- ✅ Удален словарь LOG_MESSAGES, все сообщения логирования теперь в местах вызова
- ✅ Реализована двухуровневая система логирования:
  - DEBUG логи только в файл
  - INFO/WARNING/ERROR в консоль
- ✅ Добавлено имя функции в каждую строку лога файла: `[def: имя_функции]`
- ✅ Изменен формат имени лог-файла: `LOGS_LEVEL_YYYYMMDD_HH_MM.log`
- ✅ Исправлена функция `mark_duplicates()`:
  - Имя колонки теперь формируется как `ДУБЛЬ: КЛЮЧ1_КЛЮЧ2_...` (совпадает с COLOR_SCHEME)
- ✅ Исправлена обработка CHECK_DUPLICATES:
  - Теперь обрабатываются ВСЕ записи для каждого листа (не только первая)
  - Для каждого варианта создается отдельная колонка с дублями
- ✅ Оптимизированы MERGE_FIELDS:
  - Закомментированы дублирующиеся и неиспользуемые правила
  - Удалены избыточные конфигурации

#### Улучшения логирования:
- Логи DEBUG не засоряют консоль, но сохраняются в файл для отладки
- Каждая строка лога в файле содержит информацию о функции-источнике
- Упрощен формат сообщений (прямые строки вместо словаря)

#### Улучшения проверки дублей:
- Имена колонок с дублями совпадают с цветовыми схемами
- Поддержка множественных проверок для одного листа
- Автоматическое выделение колонок с дублями розовым цветом

### Версия 1.0

#### Основные возможности:
- ✅ Базовая функциональность обработки данных
- ✅ Поддержка нечувствительности к регистру
- ✅ Относительные пути для кроссплатформенности
- ✅ Подробное логирование
- ✅ Цветовое кодирование результатов
- ✅ Разворачивание JSON полей
- ✅ Объединение данных между листами

#### Изменения в путях:
- Заменены абсолютные пути на относительные с использованием `os.path.join()`
- Добавлена поддержка нечувствительности к регистру при загрузке файлов
- Обеспечена кроссплатформенность (Windows, macOS, Linux)

## Требования

- Python 3.7+
- pandas
- openpyxl
- Стандартные библиотеки Python (os, sys, logging, datetime, json, re, csv, ast, inspect)

## Поддержка

При возникновении проблем проверьте:
1. Правильность размещения CSV файлов в каталоге `SPOD/`
2. Наличие всех необходимых зависимостей
3. Логи в каталоге `LOGS/` для диагностики ошибок (особенно DEBUG логи)
4. Права доступа к каталогам `OUT/` и `LOGS/`
5. Уровень логирования в переменной `LOG_LEVEL`

## Автор

Проект разработан для обработки данных системы SPOD (Система поддержки образовательных данных).

---

*Документация обновлена: 2025-11-14 01:15:07*
