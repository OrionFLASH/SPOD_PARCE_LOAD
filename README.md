# SPOD PROM - Система обработки и редактирования данных

## Содержание

1. [Общее описание](#общее-описание)
2. [Структура проекта](#структура-проекта)
3. [Конфигурация config.json](#конфигурация-configjson)
4. [Программа main.py - Обработка данных](#программа-mainpy---обработка-данных)
5. [Админ-панель - Редактирование данных](#админ-панель---редактирование-данных)
6. [Техническое задание](#техническое-задание)
7. [Анализ входных данных](#анализ-входных-данных)
8. [Установка и запуск](#установка-и-запуск)
9. [Логирование](#логирование)
10. [История версий](#история-версий)

---

## Общее описание

Проект состоит из двух основных компонентов:

1. **main.py** - Основная программа обработки данных из CSV файлов SPOD системы
2. **admin_panel** - Веб-интерфейс для редактирования данных через браузер

Обе программы работают с одними и теми же исходными данными, но выполняют разные задачи:
- `main.py` - читает, обрабатывает, объединяет и записывает данные в Excel
- `admin_panel` - позволяет редактировать данные через удобный веб-интерфейс

---

## Структура проекта

```
SPOD_PROM/
├── main.py                 # Основная программа обработки
├── config.json             # Конфигурация (пути, файлы, правила merge, цвета, форматы и т.д.)
├── README.md               # Документация проекта (в т.ч. полное описание config.json)
├── SPOD/                   # Исходные CSV файлы (paths.input)
├── OUT/                    # Результирующие Excel файлы (paths.output)
├── EDIT/                   # Копии файлов для редактирования (сессии админ-панели)
├── BACKUP/                 # Резервные копии
├── POST/                   # Копии основных файлов (main.py.txt, README.md.txt, config.json.txt)
├── LOGS/                   # Файлы логов (paths.logs)
├── Docs/                   # Дополнительная документация (.md, .txt)
├── admin_panel/            # Админ-панель
│   ├── app.py             # Flask приложение
│   ├── config.py          # Конфигурация
│   ├── templates/         # HTML шаблоны
│   ├── static/            # CSS, JS, изображения
│   └── utils/             # Утилиты
│       ├── file_manager.py
│       ├── data_manager.py
│       └── json_editor.py
└── venv/                  # Виртуальное окружение
```

---

## Конфигурация config.json

Все параметры обработки данных задаются в файле **config.json** в корне проекта. Программа `main.py` при запуске загружает конфиг и использует его значения. Изменение настроек не требует правки кода.

### Полный перечень секций config.json

| Секция | Назначение |
|--------|------------|
| `paths` | Каталоги: вход (SPOD), выход (OUT), логи (LOGS). |
| `logging` | Уровень (INFO/DEBUG) и базовое имя файла логов. |
| `performance` | Количество потоков: max_workers_io, max_workers_cpu. |
| `tournament_status_choices` | Подписи статусов турнира (расчёт CALC_TOURNAMENT_STATUS). |
| `input_files` | Список CSV-файлов и параметров листов Excel (имя файла, лист, ширина колонок, freeze). |
| `summary_sheet` | Параметры сводного листа SUMMARY (ширина, закрепление). |
| `summary_key_defs` | Ключевые колонки по листам для каркаса SUMMARY (порядок колонок). |
| `gender` | Правила автоопределения пола (паттерны отчества/имени/фамилии). |
| `field_length_validations` | Проверка длины полей по листам (result_column, fields с limit и operator). |
| `merge_fields_advanced` | Правила переноса/подсчёта полей между листами (источник, приёмник, ключи, column, mode). |
| `color_scheme` | Цвета заголовков и ячеек по листам и колонкам. |
| `column_formats` | Формат ячеек: число, дата, выравнивание по листам и колонкам. |
| `check_duplicates` | Правила поиска дубликатов по ключу (лист, key). |
| `json_columns` | Колонки с JSON для разворота по листам (column, prefix). |

### Общая структура файла

```json
{
  "paths": { ... },
  "logging": { ... },
  "performance": { ... },
  "tournament_status_choices": [ ... ],
  "input_files": [ ... ],
  "summary_sheet": { ... },
  "summary_key_defs": [ ... ],
  "gender": { ... },
  "field_length_validations": { ... },
  "merge_fields_advanced": [ ... ],
  "color_scheme": [ ... ],
  "column_formats": [ ... ],
  "check_duplicates": [ ... ],
  "json_columns": { ... }
}
```

---

### paths

**Назначение:** относительные имена каталогов для входных данных, выходного Excel и логов. Пути собираются программой как `(каталог_программы)/(значение)`.

| Ключ     | Тип   | Описание |
|----------|--------|----------|
| `input`  | строка | Каталог с CSV-файлами (по умолчанию `"SPOD"`). |
| `output` | строка | Каталог для сгенерированных xlsx (по умолчанию `"OUT"`). |
| `logs`   | строка | Каталог для лог-файлов (по умолчанию `"LOGS"`). |

**Пример:**
```json
"paths": {
  "input": "SPOD",
  "output": "OUT",
  "logs": "LOGS"
}
```

**Логика:** при старте программа формирует, например, `DIR_INPUT = os.path.join(BASE_DIR, paths.input)`. Файлы ищутся в `SPOD/`, результат пишется в `OUT/`, логи — в `LOGS/`.

---

### logging

**Назначение:** настройки логирования.

| Ключ        | Тип   | Описание |
|-------------|--------|----------|
| `level`     | строка | Уровень логгера: `"INFO"` (обычная работа) или `"DEBUG"` (подробный вывод в файл). |
| `base_name` | строка | Базовое имя лог-файла; к нему добавляются уровень и дата/время (например, `LOGS_INFO_20260204_22_30.log`). |

**Пример:**
```json
"logging": {
  "level": "INFO",
  "base_name": "LOGS"
}
```

**Логика:** имя файла лога: `{base_name}_{level}_{YYYYMMDD}_{HH_MM}.log` в каталоге `paths.logs`. Консоль получает только INFO и выше; в файл при `DEBUG` пишется всё.

---

### performance

**Назначение:** число потоков для параллельных операций.

| Ключ             | Тип    | Описание |
|------------------|--------|----------|
| `max_workers_io` | число  | Потоки для I/O: чтение CSV, подготовка к записи в Excel. Рекомендуется 8–16. |
| `max_workers_cpu` | число | Потоки для CPU: проверка длины полей, дубликатов и т.п. Обычно до числа ядер. |

**Пример:**
```json
"performance": {
  "max_workers_io": 16,
  "max_workers_cpu": 8
}
```

**Логика:** чтение файлов и разворот JSON идут в пуле с `max_workers_io`; проверки валидации и дубликатов — с `max_workers_cpu`. Слишком большие значения могут замедлить из-за накладных расходов.

---

### tournament_status_choices

**Назначение:** подписи статусов турнира для расчётной колонки `CALC_TOURNAMENT_STATUS`. Порядок элементов строго соответствует условиям 0–6 в `calculate_tournament_status`.

| Индекс | Условие (кратко) | Типичное значение |
|--------|-------------------|-------------------|
| 0 | Нет ключевых дат | `"НЕОПРЕДЕЛЕН"` |
| 1 | Сегодня между START_DT и END_DT | `"АКТИВНЫЙ"` |
| 2 | Сегодня &lt; START_DT | `"ЗАПЛАНИРОВАН"` |
| 3–5 | Разные варианты после END_DT / RESULT_DT | `"ПОДВЕДЕНИЕ ИТОГОВ"` |
| 6 | Все конкурсы завершены | `"ЗАВЕРШЕН"` |

**Пример:**
```json
"tournament_status_choices": [
  "НЕОПРЕДЕЛЕН",
  "АКТИВНЫЙ",
  "ЗАПЛАНИРОВАН",
  "ПОДВЕДЕНИЕ ИТОГОВ",
  "ПОДВЕДЕНИЕ ИТОГОВ",
  "ПОДВЕДЕНИЕ ИТОГОВ",
  "ЗАВЕРШЕН"
]
```

**Логика:** по датам (START_DT, END_DT, RESULT_DT, MAX_CONTEST_DATE) выбирается одно из условий; в ячейку записывается строка из массива с тем же индексом. Смена формулировок (например, «ЗАВЕРШЕН» → «ЗАВЕРШЁН») делается только в конфиге.

---

### input_files

**Назначение:** список CSV-файлов и настроек листов Excel. Каждый элемент описывает один файл и один лист в итоговой книге.

| Ключ            | Тип    | Описание |
|-----------------|--------|----------|
| `file`          | строка | Имя CSV (с расширением или без). Поиск в каталоге `paths.input` без учёта регистра (.csv / .CSV). |
| `sheet`         | строка | Имя листа в выходном Excel, куда попадут данные этого файла. |
| `max_col_width` | число  | Максимальная ширина колонки (символов) при авто-ширине. |
| `freeze`        | строка | Закрепление областей, например `"C2"` — закрепить столбцы A–B и строку 1. |
| `col_width_mode`| строка | Режим ширины: `"AUTO"` — по содержимому (ограничено max_col_width), либо число — фиксированная ширина. |
| `min_col_width` | число  | Минимальная ширина колонки. |

**Пример:**
```json
{
  "file": "CONTEST (PROM) 02-02 v2.csv",
  "sheet": "CONTEST-DATA",
  "max_col_width": 120,
  "freeze": "C2",
  "col_width_mode": "AUTO",
  "min_col_width": 12
}
```

**Логика:** программа перебирает `input_files`, для каждого ищет файл в `SPOD/`, читает CSV, разворачивает JSON по правилам из `json_columns`, затем записывает лист с именем `sheet` и применяет к нему указанные ширины и закрепление.

---

### summary_sheet

**Назначение:** параметры сводного листа «SUMMARY» (имя листа, ширина колонок, закрепление).

| Ключ            | Тип    | Описание |
|-----------------|--------|----------|
| `sheet`         | строка | Имя листа (обычно `"SUMMARY"`). |
| `max_col_width` | число  | Максимальная ширина колонки. |
| `freeze`        | строка | Закрепление (например `"G2"`). |
| `col_width_mode`| строка | Режим ширины колонок. |
| `min_col_width` | число  | Минимальная ширина. |

**Логика:** сводный лист строится по правилам `merge_fields_advanced` (где `sheet_dst` = имя из `summary_sheet.sheet`), затем к нему применяются эти параметры форматирования.

---

### summary_key_defs

**Назначение:** определение ключевых колонок по листам для построения «каркаса» сводного листа. Из этих определений программа собирает упорядоченный список всех уникальных ключей (`SUMMARY_KEY_COLUMNS`).

| Ключ   | Тип   | Описание |
|--------|--------|----------|
| `sheet`| строка | Имя листа (как в `input_files.sheet`). |
| `cols` | массив строк | Список колонок, образующих составной ключ для этого листа. |

**Пример:**
```json
{"sheet": "CONTEST-DATA", "cols": ["CONTEST_CODE"]},
{"sheet": "GROUP", "cols": ["GROUP_CODE", "CONTEST_CODE", "GROUP_VALUE"]}
```

**Логика:** из всех `cols` собирается уникальный упорядоченный список колонок. Сводный лист строится по комбинациям этих ключей, затем к строкам подтягиваются поля по правилам `merge_fields_advanced` с `sheet_dst: "SUMMARY"`.

---

### gender

**Назначение:** правила автоматического определения пола по отчеству, имени и фамилии (колонка `AUTO_GENDER` на листе EMPLOYEE).

| Ключ            | Тип  | Описание |
|-----------------|------|----------|
| `patterns`      | объект | Словарь списков окончаний для отчества, имени и фамилии (муж./жен.). |
| `progress_step` | число | Раз в сколько строк выводить прогресс в лог (например, 500). |

Ключи внутри `patterns`:

- `patronymic_male`, `patronymic_female` — окончания отчеств (например, «ович», «овна»).
- `name_male`, `name_female` — окончания имён.
- `surname_male`, `surname_female` — окончания фамилий.

**Пример (фрагмент):**
```json
"gender": {
  "patterns": {
    "patronymic_male": ["ович", "евич", "ич", "ыч", "оглы", "улы", "уулу", "заде"],
    "patronymic_female": ["овна", "евна", "инична", "ична", "на", "кызы"],
    "name_male": ["ий", "ей", "ай", "ой", "ый", "ев", "ов", "ин", "ан", "он", "ен", "ур", "ич", "ыч"],
    "name_female": ["а", "я", "ина", "ана", "ена", "ия", "ья", "на", "ла", "ра", "са", "та", "да", "ка", "га"],
    "surname_male": ["ов", "ев", "ин", "ын", "ский", "цкий", "ич", "енко", "ко", "як", "ук", "юк", "ич", "ыч"],
    "surname_female": ["ова", "ева", "ина", "ына", "ская", "цкая", "енко", "ко"]
  },
  "progress_step": 500
}
```

**Логика:** приоритет — отчество → имя → фамилия. Значение приводится к нижнему регистру и проверяется на окончание из соответствующего списка; при совпадении выставляется «М» или «Ж», иначе «-». Векторизованная версия использует те же списки.

---

### field_length_validations

**Назначение:** проверка длины полей на указанных листах. Для каждого листа задаётся результирующая колонка и правила по полям (лимит и оператор сравнения).

Структура: объект, ключи — имена листов (`"ORG_UNIT_V20"`, `"EMPLOYEE"`, `"REPORT"` и т.д.). Значение — объект:

| Ключ            | Тип   | Описание |
|-----------------|--------|----------|
| `result_column` | строка | Имя колонки с результатом проверки (например, `"FIELD_LENGTH_CHECK"`). |
| `fields`        | объект | Имя поля → правило: `{"limit": N, "operator": "=" \| "<=" \| ">="}`. |

**Пример:**
```json
"field_length_validations": {
  "EMPLOYEE": {
    "result_column": "FIELD_LENGTH_CHECK",
    "fields": {
      "PERSON_NUMBER": { "limit": 20, "operator": "=" },
      "PERSON_NUMBER_ADD": { "limit": 20, "operator": "=" }
    }
  }
}
```

**Логика:** для каждой строки листа проверяется длина указанных полей. Если длина не соответствует правилу (например, не равна 20 при `operator: "="`), в `result_column` записывается признак ошибки; иначе — «-». В конце работы программа выводит в лог и в консоль сводку по отклонениям (лист, колонка результата, количество строк с отклонениями, примеры); работа при этом не прерывается.

---

### merge_fields_advanced

**Назначение:** правила переноса и подсчёта полей между листами (объединение данных). Каждое правило задаёт источник, приёмник, ключи и список полей.

Основные поля одного правила:

| Ключ               | Тип    | Описание |
|--------------------|--------|----------|
| `sheet_src`        | строка | Лист-источник данных. |
| `sheet_dst`        | строка | Лист, куда добавляются поля. |
| `src_key`         | массив строк | Ключ(и) в источнике (например, `["CONTEST_CODE"]`). |
| `dst_key`         | массив строк | Ключ(и) в приёмнике (часто те же имена или составной ключ, например `["REWARD_LINK => CONTEST_CODE"]`). |
| `column`          | массив строк | Поля для переноса или имя поля для подсчёта (при `mode: "count"`). |
| `mode`            | строка | `"value"` — подтянуть значения; `"count"` — подсчитать количество совпадений. |
| `multiply_rows`   | bool   | При нескольких совпадениях по ключу: размножить строки в приёмнике (true) или взять одно значение (false). |
| `col_max_width`, `col_width_mode`, `col_min_width` | | Параметры ширины добавляемых колонок в Excel. |
| `status_filters`  | объект или null | Фильтр по полям в источнике (например, только `BUSINESS_STATUS` из списка). |
| `custom_conditions`, `group_by`, `aggregate` | | Доп. условия, группировка, агрегация (если используются). |
| `count_aggregation`| строка | Для `mode: "count"`: `"size"` или `"nunique"`. |
| `count_label`     | строка или null | Суффикс имени колонки счётчика (например, `"ACTIVE"` → колонка `COUNT_..._ACTIVE`). |

**Пример (подтягивание значений):**
```json
{
  "sheet_src": "CONTEST-DATA",
  "sheet_dst": "REPORT",
  "src_key": ["CONTEST_CODE"],
  "dst_key": ["CONTEST_CODE"],
  "column": ["CONTEST_TYPE", "FULL_NAME", "BUSINESS_STATUS", "BUSINESS_BLOCK", "TARGET_TYPE", "CONTEST_FEATURE => vid"],
  "mode": "value",
  "multiply_rows": false,
  "status_filters": { "BUSINESS_STATUS": ["АКТИВНЫЙ", "ПОДВЕДЕНИЕ ИТОГОВ"] }
}
```

**Пример (подсчёт):**
```json
{
  "sheet_src": "REPORT",
  "sheet_dst": "SUMMARY",
  "src_key": ["TOURNAMENT_CODE"],
  "dst_key": ["TOURNAMENT_CODE"],
  "column": ["CONTEST_DATE"],
  "mode": "count",
  "count_aggregation": "size",
  "count_label": null
}
```

**Логика:** для каждой строки листа-приёмника по `dst_key` ищутся строки в источнике по `src_key`; при `mode: "value"` подставляются значения из `column` (при нескольких совпадениях поведение задаётся `multiply_rows`); при `mode: "count"` в приёмник записывается количество (size или nunique). Поля с префиксом вида `CONTEST_FEATURE => vid` — это развёрнутые JSON-поля (имя после `=>` — ключ внутри JSON).

---

### color_scheme

**Назначение:** цветовое оформление заголовков (и при необходимости ячеек) листов Excel. Каждый элемент задаёт группу стилей, список листов и список колонок.

| Ключ         | Тип   | Описание |
|--------------|--------|----------|
| `group`      | строка | Название группы (для справки). |
| `header_bg`  | строка | Цвет фона заголовка (HEX без решётки, например `"E6F3FF"`). |
| `header_fg`  | строка | Цвет текста заголовка (HEX). |
| `column_bg`, `column_fg` | строка или null | Фон и текст для ячеек данных (если заданы). |
| `style_scope`| строка | `"header"` — стиль только для первой строки. |
| `sheets`     | массив строк | Имена листов, к которым применяется правило. |
| `columns`    | массив строк | Список колонок (заголовков). Пустой массив — все колонки листа. |

**Пример:**
```json
{
  "group": "Исходные данные",
  "header_bg": "E6F3FF",
  "header_fg": "2C3E50",
  "column_bg": null,
  "column_fg": null,
  "style_scope": "header",
  "sheets": ["CONTEST-DATA", "GROUP", "INDICATOR", "REPORT", "REWARD", "REWARD-LINK", "TOURNAMENT-SCHEDULE", "ORG_UNIT_V20", "USER_ROLE", "USER_ROLE SB", "EMPLOYEE"],
  "columns": []
}
```

**Логика:** при формировании Excel для каждого листа из `sheets` к заголовкам (и при необходимости к ячейкам) из `columns` применяется заливка и цвет шрифта. Порядок правил важен: последующие могут перекрывать предыдущие для тех же колонок.

---

### column_formats

**Назначение:** формат ячеек Excel по листам и колонкам (число, дата, выравнивание, перенос).

Каждый элемент — объект:

| Ключ                 | Тип    | Описание |
|----------------------|--------|----------|
| `sheet`              | строка | Имя листа. |
| `columns`            | массив строк | Имена колонок (заголовков). |
| `data_type`          | строка | `"number"`, `"date"` или `"text"`. |
| `decimal_places`     | число  | Для числа — знаков после запятой (0 — целые). |
| `decimal_separator`  | строка | Разделитель дробной части: `","` или `"."`. |
| `thousands_separator`| bool   | Разделитель разрядов в целой части. |
| `date_format`        | строка | Для даты: например `"YYYY-MM-DD"` или `"DD/MM/YYYY"`. |
| `horizontal`, `vertical` | строка | Выравнивание: `"left"`/`"center"`/`"right"`, `"top"`/`"center"`/`"bottom"`. |
| `wrap_text`          | bool   | Перенос по словам. |

**Пример:**
```json
{
  "sheet": "INDICATOR",
  "columns": ["N", "CALC_TYPE", "INDICATOR_WEIGHT", "INDICATOR_CALC_TYPE"],
  "data_type": "number",
  "decimal_places": 0,
  "decimal_separator": ",",
  "thousands_separator": false,
  "date_format": "YYYY-MM-DD",
  "horizontal": "center",
  "vertical": "center",
  "wrap_text": false
}
```

**Логика:** при записи в Excel данные в указанных колонках приводятся к числу или дате (в т.ч. замена запятой на точку при парсе); в книге задаётся числовой/датовый формат и выравнивание. Для `decimal_places: 0` в ячейку записываются целые числа без дробной части.

---

### check_duplicates

**Назначение:** правила поиска дубликатов по ключу на заданных листах. Для каждой комбинации ключа добавляется колонка вида «ДУБЛЬ: KEY1_KEY2_...» с признаком дубля.

| Ключ   | Тип   | Описание |
|--------|--------|----------|
| `sheet`| строка | Имя листа. |
| `key`  | массив строк | Список колонок, по которым определяется дубликат. |

**Пример:**
```json
{"sheet": "CONTEST-DATA", "key": ["CONTEST_CODE"]},
{"sheet": "GROUP", "key": ["CONTEST_CODE", "GROUP_CODE", "GROUP_VALUE"]},
{"sheet": "EMPLOYEE", "key": ["PERSON_NUMBER"]},
{"sheet": "EMPLOYEE", "key": ["PERSON_NUMBER_ADD"]}
```

**Логика:** для листа по полям `key` считается количество повторений комбинации; если больше 1, в новой колонке «ДУБЛЬ: ...» ставится признак дубликата. Одна запись в конфиге — одна такая колонка (на одном листе может быть несколько правил с разными ключами). В конце работы программа выводит в лог и в консоль итоговую статистику: на каком листе найден дубликат, по какому ключу, задублированные значения и количество вхождений; работа при этом не прерывается.

---

### json_columns

**Назначение:** какие колонки в каких листах считать JSON и разворачивать в отдельные колонки. Задаётся по имени листа.

Структура: объект, ключи — имена листов. Значение — массив объектов:

| Ключ    | Тип   | Описание |
|---------|--------|----------|
| `column`| строка | Имя колонки с JSON-строкой. |
| `prefix`| строка | Префикс для имён новых колонок (например, `"CONTEST_FEATURE"` или `"ADD_DATA"`). Вложенные ключи дают имена вида `prefix => key` или `prefix => key => nested`. |

**Пример:**
```json
"json_columns": {
  "CONTEST-DATA": [
    { "column": "CONTEST_FEATURE", "prefix": "CONTEST_FEATURE" }
  ],
  "REWARD": [
    { "column": "REWARD_ADD_DATA", "prefix": "ADD_DATA" }
  ]
}
```

**Логика:** при загрузке листа каждая указанная колонка парсится как JSON; ключи верхнего уровня становятся колонками `prefix => key`; вложенные объекты/массивы разворачиваются рекурсивно с тем же префиксом. Исходная колонка сохраняется; при необходимости тройные кавычки в исходных данных обрабатываются отдельно (CONTEST_FEATURE).

---

## Программа main.py - Обработка данных

### Назначение

Основная программа для обработки данных из CSV файлов системы SPOD. Программа:
- Загружает параметры из **config.json** (пути, списки файлов, правила объединения, проверки и т.д.)
- Читает CSV файлы из каталога, заданного в `paths.input` (по умолчанию `SPOD/`)
- Обрабатывает данные согласно правилам объединения (`merge_fields_advanced`)
- Проверяет дубликаты (`check_duplicates`)
- Создаёт итоговый Excel файл с несколькими листами
- Ведёт подробное логирование всех операций

### Входные данные

Программа работает с CSV-файлами, перечисленными в `config.json` в секции **input_files** (имя файла и листа для каждого источника). Примеры листов:

1. **CONTEST-DATA** - Данные о конкурсах
2. **EMPLOYEE** - Данные о сотрудниках
3. **GROUP** - Группы
4. **INDICATOR** - Индикаторы
5. **ORG_UNIT_V20** - Организационные единицы
6. **REPORT** - Отчеты
7. **REWARD** - Награды
8. **REWARD-LINK** - Связи наград
9. **TOURNAMENT-SCHEDULE** - Расписание турниров
10. **TOURNAMENT-SCHEDULE-LINK** - Связи расписания
11. **TOURNAMENT-SCHEDULE-LINK_CONTEST** - Связи расписания с конкурсами

### Основная логика работы

#### 1. Инициализация и настройка

При импорте модуля выполняется загрузка **config.json** (пути, `input_files`, `merge_fields_advanced`, `check_duplicates`, логирование, цветовая схема и др.). Далее:

```python
# Настройка логирования (использует logging.level и logging.base_name из config)
setup_logger()  # Создаёт логгер: DEBUG в файл, INFO в консоль
# Все параметры (INPUT_FILES, MERGE_FIELDS_ADVANCED, CHECK_DUPLICATES и т.д.) уже загружены из config.json
```

#### 2. Чтение CSV файлов

```python
def read_csv_file(file_path):
    # Читает CSV с разделителем ";"
    # Обрабатывает кодировку UTF-8
    # Возвращает DataFrame
```

**Особенности:**
- Автоматическое определение файла по дате в имени
- Обработка различных форматов дат в именах файлов
- Пропуск некорректных строк (`on_bad_lines='skip'`)

#### 3. Обработка данных

##### 3.1. Объединение данных (merge_fields_advanced)

Программа объединяет данные из разных файлов по правилам из **config.json** → `merge_fields_advanced`. Каждое правило задаёт источник, приёмник, ключи и поля (подробнее см. раздел [Конфигурация config.json](#конфигурация-configjson) → merge_fields_advanced).

```json
{
  "sheet_src": "SOURCE_SHEET",
  "sheet_dst": "DEST_SHEET",
  "src_key": ["SOURCE_KEY"],
  "dst_key": ["DEST_KEY"],
  "column": ["FIELD1", "FIELD2"],
  "mode": "value",
  "multiply_rows": false
}
```

**Режимы объединения:**
- `merge` - Объединение полей (добавление новых колонок)
- `count` - Подсчет количества записей
- `sum` - Суммирование значений

##### 3.2. Проверка дубликатов (check_duplicates из config.json)

Правила задаются в **config.json** в секции `check_duplicates`. Каждый элемент: `"sheet"` — имя листа, `"key"` — массив колонок для проверки.

**Логика:**
- Находит записи с одинаковыми значениями в ключевых колонках
- Добавляет колонку «ДУБЛЬ: KEY1_KEY2_...» с меткой (например, «x2») при повторении комбинации ключа
- В конце работы выводит сводку по дубликатам в лог и консоль (лист, ключ, задублированные значения)

##### 3.3. Обработка JSON полей

Некоторые поля содержат JSON данные:
- `CONTEST_FEATURE` (CONTEST-DATA)
- `CONTEST_PERIOD` (CONTEST-DATA)
- `BUSINESS_BLOCK` (CONTEST-DATA)
- `TARGET_TYPE` (TOURNAMENT-SCHEDULE)
- `FILTER_PERIOD_ARR` (TOURNAMENT-SCHEDULE)
- `INDICATOR_FILTER` (INDICATOR)
- `GROUP_VALUE` (GROUP)
- `REWARD_ADD_DATA` (REWARD)

Эти поля обрабатываются как строки и сохраняются в исходном виде.

#### 4. Запись в Excel

```python
def write_to_excel(sheets_data, output_path):
    # Создает Excel файл с несколькими листами
    # Сохраняет порядок листов
    # Применяет цветовую схему для дубликатов
```

**Структура Excel файла:**
- Каждый исходный файл → отдельный лист
- Листы упорядочены согласно `ordered_sheets`
- Применяется цветовая схема для дубликатов

#### 5. Итоговая статистика (дубликаты и валидация длины полей)

После записи в Excel программа формирует отчёт и выводит его **в лог и в консоль** (без прерывания работы):

- **Дубликаты** (по правилам `check_duplicates`): для каждого листа, где найдены дубликаты — имя листа, ключ (колонки), имя колонки проверки, число строк с дубликатами, задублированные значения ключей и количество вхождений.
- **Отклонения по длине полей** (по правилам `field_length_validations`): для каждого листа с нарушениями — имя листа, колонка результата, число строк с отклонениями, примеры текста нарушений (до 10).

Функции: `collect_duplicates_and_validation_report(sheets_data)` — сбор данных; `print_final_report(duplicates_report, validation_report)` — вывод в лог и консоль.

### Логирование

Программа ведет два уровня логирования:

1. **DEBUG** (в файл):
   - Все операции чтения/записи
   - Детали обработки данных
   - Ошибки с полным stack trace
   - Формат: `дата время - [DEBUG] - сообщение [class: ClassName | def: function_name]`

2. **INFO** (в консоль):
   - Основные этапы выполнения
   - Критические ошибки
   - Итоговая статистика

**Именование логов:**
- Формат: `LOGS_DEBUG_YYYYMMDD_HH_MM.log`
- Расположение: `LOGS/`

---

## Админ-панель - Редактирование данных

### Назначение

Веб-интерфейс для редактирования данных из CSV файлов через браузер. Позволяет:
- Просматривать данные всех файлов
- Редактировать записи
- Создавать новые записи
- Удалять записи
- Редактировать JSON поля
- Работать с несколькими сессиями редактирования

### Архитектура

#### Backend (Flask)

**app.py** - Основное Flask приложение:
- REST API для работы с данными
- Управление сессиями редактирования
- Обработка CRUD операций

**Основные endpoints:**
```
GET  /api/sessions              # Список сессий
POST /api/session/new           # Создание новой сессии
POST /api/session/<name>        # Переключение сессии
DELETE /api/session/<name>      # Удаление сессии
GET  /api/files                  # Список файлов
GET  /api/files/<key>/records   # Записи файла
GET  /api/files/<key>/records/<id>  # Одна запись
POST /api/files/<key>/records   # Создание записи
PUT  /api/files/<key>/records/<id>   # Обновление записи
DELETE /api/files/<key>/records/<id> # Удаление записи
```

**config.py** - Конфигурация:
- Динамическое чтение `INPUT_FILES` из `main.py`
- Определение JSON полей
- Зависимости между файлами
- Многострочные поля

**utils/file_manager.py** - Управление файлами:
- Чтение/запись CSV
- Управление сессиями (создание, удаление)
- Резервное копирование

**utils/data_manager.py** - Управление данными:
- CRUD операции
- Валидация данных
- Обработка JSON полей
- Проверка зависимостей

#### Frontend (HTML/CSS/JavaScript)

**templates/index.html** - Главная страница:
- Интерфейс с вкладками для файлов
- Формы редактирования
- Модальные окна для JSON редактора

**static/js/app.js** - Клиентская логика:
- Загрузка и отображение данных
- Управление сессиями
- CRUD операции через API
- JSON редактор

**static/css/style.css** - Стили:
- Современный дизайн
- Адаптивная верстка
- Цветовая схема

### Логика работы админ-панели

#### 1. Инициализация

При загрузке страницы:
1. Загружается список сессий из `EDIT/`
2. Выбирается последняя сессия (или создается новая)
3. Загружается список файлов из `main.py`
4. Создаются вкладки для каждого файла
5. Загружаются записи первого файла

#### 2. Управление сессиями

**Создание сессии:**
1. Создается каталог `EDIT/YYYYMMDD_HHMM/`
2. Копируются все файлы из `SPOD/`
3. Сессия добавляется в список
4. Автоматически выбирается как текущая

**Переключение сессии:**
1. Меняется `current_edit_dir` в `FileManager`
2. Перезагружаются данные
3. Обновляется интерфейс

**Удаление сессии:**
1. Проверяется что сессия не текущая
2. Удаляется каталог со всеми файлами
3. Обновляется список сессий

#### 3. Работа с данными

**Чтение записей:**
- Пагинация (по умолчанию 50 записей на страницу)
- Поиск по всем полям или по конкретному полю (`field:value`)
- Сортировка по колонкам
- Сохранение порядка колонок из исходного файла

**Редактирование записи:**
1. Загружается запись по ID
2. Отображается форма с полями
3. JSON поля отображаются в специальном редакторе
4. При сохранении проверяются зависимости
5. Обновляется файл в текущей сессии

**Создание записи:**
1. Отображается пустая форма
2. Заполняются обязательные поля
3. Проверяются зависимости
4. Добавляется запись в конец файла

**Удаление записи:**
1. Проверяются зависимости (если запись используется в других файлах)
2. Показывается предупреждение
3. Удаляется запись из файла

#### 4. Обработка JSON полей

**Определение JSON полей:**
```python
JSON_FIELDS = {
    "CONTEST-DATA": ["CONTEST_FEATURE", "CONTEST_PERIOD", "BUSINESS_BLOCK"],
    "TOURNAMENT-SCHEDULE": ["TARGET_TYPE", "FILTER_PERIOD_ARR"],
    "INDICATOR": ["INDICATOR_FILTER"],
    "GROUP": ["GROUP_VALUE"],
    "REWARD": ["REWARD_ADD_DATA"]
}
```

**Редактирование JSON:**
- Отдельный редактор для JSON полей
- Валидация JSON структуры
- Поддержка зависимостей (например, структура `REWARD_ADD_DATA` зависит от `REWARD_TYPE`)
- Автодополнение полей и значений

#### 5. Зависимости между файлами

```python
FILE_DEPENDENCIES = {
    "GROUP": {"parent": "CONTEST-DATA", "parent_key": "CONTEST_CODE", "child_key": "CONTEST_CODE"},
    "INDICATOR": {"parent": "CONTEST-DATA", "parent_key": "CONTEST_CODE", "child_key": "CONTEST_CODE"},
    "REWARD-LINK": {"parent": "REWARD", "parent_key": "REWARD_CODE", "child_key": "REWARD_CODE"},
    # ...
}
```

При удалении записи проверяется:
- Используется ли она в дочерних файлах
- Показывается список зависимых записей
- Предлагается удалить зависимые записи

### Логирование админ-панели

**Серверные логи:**
- Формат: `LOGS_DEBUG_admin_panel_YYYYMMDD_HHMM.log`
- Расположение: `LOGS/`
- Уровни: DEBUG (файл), INFO (консоль)

**Клиентские логи:**
- Консоль браузера (F12)
- Логирование всех API запросов
- Детали ошибок

---

## Техническое задание

### Требования к main.py

1. **Чтение данных:**
   - Поддержка CSV с разделителем ";"
   - Кодировка UTF-8
   - Автоматическое определение файлов по дате

2. **Обработка данных:**
   - Объединение данных по правилам `MERGE_FIELDS`
   - Проверка дубликатов по правилам `CHECK_DUPLICATES`
   - Сохранение исходного порядка колонок

3. **Запись результатов:**
   - Excel файл с несколькими листами
   - Цветовая маркировка дубликатов
   - Сохранение всех исходных данных

4. **Логирование:**
   - DEBUG уровень в файл
   - INFO уровень в консоль
   - Формат с указанием функции

### Требования к админ-панели

1. **Функциональность:**
   - Просмотр всех файлов через вкладки
   - CRUD операции для всех записей
   - Редактирование JSON полей
   - Управление сессиями редактирования

2. **Интерфейс:**
   - Современный дизайн
   - Адаптивная верстка
   - Удобная навигация

3. **Валидация:**
   - Проверка обязательных полей
   - Проверка зависимостей
   - Валидация JSON

4. **Безопасность:**
   - Работа только с копиями файлов
   - Резервное копирование
   - Изоляция сессий

---

## Анализ входных данных

### Структура файлов

Все файлы имеют структуру CSV с разделителем ";" и кодировкой UTF-8.

### JSON поля

В 5 файлах обнаружено 8 JSON полей:

1. **CONTEST-DATA:**
   - `CONTEST_FEATURE` - объект с признаками конкурса
   - `CONTEST_PERIOD` - массив периодов
   - `BUSINESS_BLOCK` - массив строк

2. **TOURNAMENT-SCHEDULE:**
   - `TARGET_TYPE` - объект с `seasonCode`
   - `FILTER_PERIOD_ARR` - массив объектов

3. **INDICATOR:**
   - `INDICATOR_FILTER` - массив объектов

4. **GROUP:**
   - `GROUP_VALUE` - массив чисел или строка

5. **REWARD:**
   - `REWARD_ADD_DATA` - объект (структура зависит от `REWARD_TYPE`)

### Зависимости между файлами

- **GROUP** → **CONTEST-DATA** (по `CONTEST_CODE`)
- **INDICATOR** → **CONTEST-DATA** (по `CONTEST_CODE`)
- **TOURNAMENT-SCHEDULE** → **CONTEST-DATA** (по `CONTEST_CODE`)
- **REPORT** → **TOURNAMENT-SCHEDULE** (по `TOURNAMENT_CODE`, `CONTEST_CODE`)
- **REWARD-LINK** → **REWARD** (по `REWARD_CODE`)
- **REWARD-LINK** → **CONTEST-DATA** (по `CONTEST_CODE`)
- **REWARD-LINK** → **GROUP** (по `CONTEST_CODE`, `GROUP_CODE`)

### Многострочные поля

- **REWARD-LINK.GROUP_CODE** - список значений через запятую

---

## Установка и запуск

### Требования

- Python 3.8+
- pip
- Виртуальное окружение (рекомендуется)

### Установка main.py

```bash
# Создание виртуального окружения
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# или
venv\Scripts\activate  # Windows

# Установка зависимостей
pip install pandas openpyxl

# Запуск
python main.py
```

### Установка админ-панели

```bash
# Переход в каталог админ-панели
cd admin_panel

# Создание виртуального окружения (если нужно)
python3 -m venv venv
source venv/bin/activate

# Установка зависимостей
pip install -r requirements.txt

# Запуск
python app.py
# или
./start.sh
```

Админ-панель будет доступна по адресу: `http://localhost:5001`

---

## Логирование

### Формат логов

**DEBUG уровень (в файл):**
```
2025-11-14 03:02:51,034 | DEBUG | __main__ | <module> | Запуск сервера админ-панели... [class: None | def: <module>]
```

**INFO уровень (в консоль):**
```
2025-11-14 03:02:51,034 | INFO | __main__ | <module> | Запуск сервера админ-панели...
```

### Именование файлов логов

- `main.py`: `LOGS_DEBUG_YYYYMMDD_HH_MM.log`
- `admin_panel`: `LOGS_DEBUG_admin_panel_YYYYMMDD_HHMM.log`

### Расположение

Все логи сохраняются в каталоге `LOGS/`

---

## История версий

### Версия 1.0 (Текущая)

**Основные изменения:**
- Реализована основная программа обработки данных (`main.py`)
- Вся конфигурация вынесена в **config.json** (пути, input_files, summary_key_defs, gender, field_length_validations, merge_fields_advanced, color_scheme, column_formats, check_duplicates, json_columns)
- Создана админ-панель для редактирования данных
- Настроено логирование с двумя уровнями
- Реализована проверка дубликатов по правилам из config
- Итоговая статистика по дубликатам и отклонениям длины полей в лог и консоль в конце работы (без прерывания)
- Добавлена поддержка JSON полей (разворот по json_columns)
- Реализовано управление сессиями редактирования
- Документация собрана в корневом README.md и каталоге Docs/; копии main.py, README.md, config.json сохраняются в POST/ с суффиксом .txt

**Исправленные проблемы:**
- Исправлен порядок колонок в админ-панели
- Добавлено детальное логирование ошибок
- Исправлена обработка JSON полей
- Улучшена валидация данных
- Исправлена работа с зависимостями между файлами

**Оптимизации:**
- Удалены неиспользуемые функции создания SUMMARY листов
- Улучшена производительность чтения CSV
- Оптимизирована работа с большими файлами

---

## Контакты и поддержка

Для вопросов и предложений обращайтесь к разработчику проекта.

---

*Документация обновлена: 2026-01-31*
